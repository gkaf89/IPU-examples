{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) 2022 Graphcore Ltd. All rights reserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tgn_modules import TGN, Data\n",
    "import torch\n",
    "import poptorch\n",
    "from tqdm import tqdm\n",
    "import time, copy, pickle\n",
    "\n",
    "data_path = 'data/JODIE'\n",
    "data = Data(data_path, torch.float32)\n",
    "\n",
    "memory_dim = time_dim = embedding_dim = 100\n",
    "raw_msg_dim = 172\n",
    "num_nodes = 9227\n",
    "\n",
    "tgn = TGN(\n",
    "    num_nodes,\n",
    "    raw_msg_dim,\n",
    "    memory_dim,\n",
    "    time_dim,\n",
    "    embedding_dim,\n",
    "    dtype=torch.float32,\n",
    ")\n",
    "\n",
    "tgn.train()\n",
    "\n",
    "\n",
    "opts = poptorch.Options()\n",
    "opts.Precision.enableFloatingPointExceptions(True)\n",
    "\n",
    "# anchor all gradients\n",
    "for nm, _ in tgn.named_parameters():\n",
    "    opts.anchorTensor(nm, f'Gradient___model.{nm}')\n",
    "\n",
    "optim = poptorch.optim.Adam(tgn.parameters(), lr=1e-4)\n",
    "tgn = poptorch.trainingModel(tgn, options=opts, optimizer=optim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_params = copy.deepcopy(dict(list(tgn.named_parameters())))   \n",
    "pickle.dump(orig_params, open(\"/tmp/ipu_ini_params.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.7397,  0.2817,  0.3520,  0.9623, -0.1636, -0.9807,  0.8095,  0.2811,\n",
       "         0.4082,  0.1483, -0.8273,  0.1099, -0.1908, -0.1715, -0.4458,  0.0576,\n",
       "        -0.5146,  0.8772,  0.1659,  0.5032,  0.3383, -0.0848,  0.4635, -0.3792,\n",
       "        -0.5816,  0.3672, -0.2853, -0.1377,  0.7425,  0.6891, -0.9273, -0.4603,\n",
       "        -0.9612,  0.7262,  0.6213, -0.1404, -0.4877, -0.7073, -0.7684, -0.0055,\n",
       "         0.2507,  0.6931, -0.5887,  0.2587, -0.8217, -0.6690,  0.0972,  0.5272,\n",
       "         0.8913,  0.2911, -0.3270,  0.6427, -0.9082, -0.1520, -0.5832,  0.7577,\n",
       "         0.6893, -0.5333,  0.7599,  0.9738, -0.7304, -0.3465, -0.6661, -0.6086,\n",
       "         0.8264,  0.8913, -0.8410, -0.9594,  0.1996,  0.4596, -0.4624, -0.8702,\n",
       "         0.0460, -0.6078,  0.4202,  0.8099,  0.2462,  0.8838, -0.3461,  0.1081,\n",
       "         0.3908, -0.9536, -0.3709,  0.7139, -0.0964, -0.6284,  0.2954, -0.1972,\n",
       "        -0.0249, -0.6908, -0.4990, -0.9492,  0.5262,  0.1728,  0.0188,  0.1511,\n",
       "        -0.0662, -0.3019, -0.9887,  0.5284], requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tgn.memory.time_enc.lin.bias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:26:38.755] [poptorch::python] [warning] At least one input tensor is not contiguous: non-contiguous tensors will be converted.\n",
      "/localdata/gianandream/gnn/tgn_modules.py:463: TracerWarning: Converting a tensor to a Python index might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  broad_ix = torch.stack([indices] * n_cols, 1)\n",
      "Graph compilation: 100%|██████████| 100/100 [02:03<00:00]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.3867])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(data.batches('train'))\n",
    "\n",
    "optim.zero_grad()\n",
    "loss = tgn(**batch)\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {}\n",
    "gradients = {}\n",
    "\n",
    "for nm, val in tgn.named_parameters():\n",
    "    params[nm] = val\n",
    "    gradients[nm] = tgn.getAnchoredTensor(nm)\n",
    "\n",
    "pickle.dump(params, open(\"/tmp/ipu_fin_params.pkl\", \"wb\"))\n",
    "pickle.dump(gradients, open(\"/tmp/ipu_gradients.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory.time_enc.lin.weight difference: 0.000\n",
      "memory.time_enc.lin.bias difference: 0.003\n",
      "memory.gru.weight_ih difference: 0.055\n",
      "memory.gru.weight_hh difference: 0.000\n",
      "memory.gru.bias_ih difference: 0.005\n",
      "memory.gru.bias_hh difference: 0.005\n",
      "gnn.conv.lin_key.weight difference: 0.032\n",
      "gnn.conv.lin_key.bias difference: 0.003\n",
      "gnn.conv.lin_query.weight difference: 0.032\n",
      "gnn.conv.lin_query.bias difference: 0.003\n",
      "gnn.conv.lin_value.weight difference: 0.000\n",
      "gnn.conv.lin_value.bias difference: 0.000\n",
      "gnn.conv.lin_edge.weight difference: 0.032\n",
      "gnn.conv.lin_skip.weight difference: 0.031\n",
      "gnn.conv.lin_skip.bias difference: 0.003\n",
      "link_predictor.lin_hid.weight difference: 0.030\n",
      "link_predictor.lin_hid.bias difference: 0.002\n",
      "link_predictor.lin_final.weight difference: 0.002\n",
      "link_predictor.lin_final.bias difference: 0.000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for nm, val in orig_params.items():\n",
    "    diff = float(torch.norm(val - params[nm]))\n",
    "    print(f\"{nm} difference: {diff:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 ('3.0.0-EA.1+1096_tf2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "28a31b298b5cf82e7ec0025eec015e7dafd43029fa5251b52ec025705400dfdc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
